{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo create pointing network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertLayer, BertConfig, BertAttention\n",
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_config = BertConfig(num_attention_heads=1, hidden_size=768, num_hidden_layers=2, intermediate_size=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pointer network\n",
    "tag_embedding = torch.nn.Embedding(12,5)\n",
    "pos_embedding = torch.nn.Embedding(100,5)\n",
    "\n",
    "# Linear SWISH GELU\n",
    "linear = torch.nn.Linear(5,5)\n",
    "swish = torch.nn.SiLU()\n",
    "gelu = torch.nn.GELU()\n",
    "\n",
    "# 2x encoder\n",
    "encoder = BertLayer(pointer_config)\n",
    "\n",
    "# Attention Layer! (single head)\n",
    "attention = BertAttention(pointer_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train_with_pointing.csv\")\n",
    "data_train = datasets.Dataset.from_pandas(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['informal', 'formal', 'point_indexes', 'label', 'len_label'],\n",
       "    num_rows: 1922\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_label_extract = data_train.to_pandas().point_labels.apply(lambda x: ' '.join([str(z) for z in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>informal</th>\n",
       "      <th>formal</th>\n",
       "      <th>point_indexes</th>\n",
       "      <th>label</th>\n",
       "      <th>len_label</th>\n",
       "      <th>tag_labels</th>\n",
       "      <th>point_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>sudah , harga barang xnumberx xnumberx xnumberx k , ongkir xnumberx xnumberx k , diskon xnumberx xnumberx k , biaya penanganan xnumberx , xnumberx k . seharusnya saya bayar xnumberx , xnumberx k saja , tapi malah ditagih xnumberx , xnumberx k .</td>\n",
       "      <td>sudah , harga barang xnumberx ribu , onkir xnumberx ribu , diskon xnumberx ribu , biaya penanganan xnumberx ribu . seharusnya saya bayar xnumberx ribu saja , tapi malah ditagih xnumberx ribu .</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 21, 22, 23, 24, 30, 0, 0, 0, 0, 0, 31, 32, 33, 34, 35, 41, 0, 0, 0, 0, 0, 42, 43, 44, 45, 46, 47, 54, 0, 0, 0, 0, 0, 0, 55, 56, 57, 58, 59, 60, 61, 68, 0, 0, 0, 0, 0, 0, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 85, 0, 0, 0, 0, 0, 0, 86, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2]</td>\n",
       "      <td>87</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 21, 22, 23, 24, 30, 0, 0, 0, 0, 0, 31, 32, 33, 34, 35, 41, 0, 0, 0, 0, 0, 42, 43, 44, 45, 46, 47, 54, 0, 0, 0, 0, 0, 0, 55, 56, 57, 58, 59, 60, 61, 68, 0, 0, 0, 0, 0, 0, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 85, 0, 0, 0, 0, 0, 0, 86, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                  informal  \\\n",
       "1220  sudah , harga barang xnumberx xnumberx xnumberx k , ongkir xnumberx xnumberx k , diskon xnumberx xnumberx k , biaya penanganan xnumberx , xnumberx k . seharusnya saya bayar xnumberx , xnumberx k saja , tapi malah ditagih xnumberx , xnumberx k .   \n",
       "\n",
       "                                                                                                                                                                                                formal  \\\n",
       "1220  sudah , harga barang xnumberx ribu , onkir xnumberx ribu , diskon xnumberx ribu , biaya penanganan xnumberx ribu . seharusnya saya bayar xnumberx ribu saja , tapi malah ditagih xnumberx ribu .   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                      point_indexes  \\\n",
       "1220  [1, 2, 3, 4, 5, 6, 7, 8, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 21, 22, 23, 24, 30, 0, 0, 0, 0, 0, 31, 32, 33, 34, 35, 41, 0, 0, 0, 0, 0, 42, 43, 44, 45, 46, 47, 54, 0, 0, 0, 0, 0, 0, 55, 56, 57, 58, 59, 60, 61, 68, 0, 0, 0, 0, 0, 0, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 85, 0, 0, 0, 0, 0, 0, 86, 0]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                      label  \\\n",
       "1220  [2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2]   \n",
       "\n",
       "      len_label  \\\n",
       "1220  87          \n",
       "\n",
       "                                                                                                                                                                                                                                                                 tag_labels  \\\n",
       "1220  [2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 3, 2, 2]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                       point_labels  \n",
       "1220  [1, 2, 3, 4, 5, 6, 7, 8, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 21, 22, 23, 24, 30, 0, 0, 0, 0, 0, 31, 32, 33, 34, 35, 41, 0, 0, 0, 0, 0, 42, 43, 44, 45, 46, 47, 54, 0, 0, 0, 0, 0, 0, 55, 56, 57, 58, 59, 60, 61, 68, 0, 0, 0, 0, 0, 0, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 85, 0, 0, 0, 0, 0, 0, 86, 0]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.to_pandas()[tag_label_extract.str.contains(\"86\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "len_label\n",
       "20     97\n",
       "13     93\n",
       "14     92\n",
       "16     91\n",
       "19     88\n",
       "11     84\n",
       "21     82\n",
       "17     80\n",
       "15     80\n",
       "12     74\n",
       "18     73\n",
       "22     70\n",
       "25     64\n",
       "10     62\n",
       "28     61\n",
       "31     59\n",
       "9      56\n",
       "23     56\n",
       "26     52\n",
       "24     51\n",
       "27     50\n",
       "29     47\n",
       "32     42\n",
       "30     40\n",
       "35     36\n",
       "33     35\n",
       "8      27\n",
       "34     27\n",
       "37     26\n",
       "36     22\n",
       "38     16\n",
       "39     11\n",
       "40     11\n",
       "41     8 \n",
       "43     8 \n",
       "47     5 \n",
       "42     5 \n",
       "48     5 \n",
       "46     5 \n",
       "54     4 \n",
       "71     3 \n",
       "52     2 \n",
       "45     2 \n",
       "88     2 \n",
       "60     2 \n",
       "44     2 \n",
       "65     1 \n",
       "49     1 \n",
       "100    1 \n",
       "51     1 \n",
       "84     1 \n",
       "59     1 \n",
       "73     1 \n",
       "50     1 \n",
       "55     1 \n",
       "93     1 \n",
       "82     1 \n",
       "7      1 \n",
       "57     1 \n",
       "76     1 \n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.to_pandas().len_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dict(max_mask=3, use_pointing=True):\n",
    "    label_map = {'PAD': 0, 'SWAP': 1, 'KEEP': 2, 'DELETE': 3}\n",
    "    # Create Insert 1 MASK to insertion N MASKS.\n",
    "    for i in range(1, max_mask+1):\n",
    "        label_map[f'KEEP|{i}'] = len(label_map)\n",
    "    if not use_pointing:\n",
    "        label_map[f'DELETE|{i}'] = len(label_map)\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 85,\n",
       " 86}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = []\n",
    "for x in data_train.to_pandas().point_labels:\n",
    "    agg.extend(x)\n",
    "set(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "99 in agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = create_label_dict(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbee import compute_edits_and_insertions\n",
    "from insert_convert import InsertionConverter, get_number_of_masks\n",
    "from trying import PointingConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_converter = PointingConverter({}, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_src_tgt(examples, tokenizer, src=\"informal\", tgt=\"formal\"):\n",
    "    returned_dict = {f\"{src}_{i}\": j for i,j in tokenizer(examples[src]).items()}\n",
    "    returned_dict.update({f\"{tgt}_{i}\": j for i,j in tokenizer(examples[tgt]).items()})\n",
    "    return returned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1922/1922 [00:00<00:00, 14200.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_train = data_train.map(\n",
    "    tokenize_function_src_tgt,\n",
    "    batched=True,\n",
    "    fn_kwargs={\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"indolem/indobert-base-uncased\")\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['informal', 'formal', 'point_indexes', 'label', 'len_label', 'tag_labels', 'point_labels', 'informal_input_ids', 'informal_token_type_ids', 'informal_attention_mask', 'formal_input_ids', 'formal_token_type_ids', 'formal_attention_mask'],\n",
       "    num_rows: 1922\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pointer_labels(points, label_map):\n",
    "    labels = [t.added_phrase for t in points]\n",
    "    point_indexes = [t.point_index for t in points]\n",
    "    point_indexes_set = set(point_indexes)\n",
    "    new_labels = []\n",
    "    for i, added_phrase in enumerate(labels):\n",
    "        if i not in point_indexes_set:\n",
    "            new_labels.append(label_map[\"DELETE\"])\n",
    "        elif not added_phrase:\n",
    "            new_labels.append(label_map[\"KEEP\"])\n",
    "        else:\n",
    "            new_labels.append(label_map[\"KEEP|\" + str(len(added_phrase.split()))])\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokenized(examples, tokenizer, label_dict, point_converter, src=\"informal\", tgt=\"formal\"):\n",
    "    src_tokenized = tokenizer.tokenize(examples[src], add_special_tokens=True)\n",
    "    tgt_tokenized = tokenizer.tokenize(examples[tgt], add_special_tokens=True)\n",
    "    points = point_converter.compute_points(src_tokenized, ' '.join(tgt_tokenized))\n",
    "    label = create_pointer_labels(points, label_dict)\n",
    "    point_indexes = [t.point_index for t in points] \n",
    "    # change them to torch tensors\n",
    "    label = label\n",
    "    point_indexes = point_indexes\n",
    "    return {f\"tag_labels\": label, f\"point_labels\": point_indexes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"indolem/indobert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1922 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1922/1922 [00:00<00:00, 2160.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_train = data_train.map(\n",
    "    generate_tokenized,\n",
    "    batched=False,\n",
    "    fn_kwargs={\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"label_dict\": label_dict,\n",
    "        \"point_converter\": point_converter\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['informal', 'formal', 'point_indexes', 'label', 'len_label', 'tag_labels', 'point_labels', 'informal_input_ids', 'informal_token_type_ids', 'informal_attention_mask', 'formal_input_ids', 'formal_token_type_ids', 'formal_attention_mask'],\n",
       "    num_rows: 1922\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train['point_labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train['formal_input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['informal', 'formal', 'point_indexes', 'label', 'len_label', 'tag_labels', 'point_labels', 'informal_input_ids', 'informal_token_type_ids', 'informal_attention_mask', 'formal_input_ids', 'formal_token_type_ids', 'formal_attention_mask'],\n",
       "    num_rows: 1922\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_koto = BertForTokenClassification.from_pretrained(\"indolem/indobert-base-uncased\", num_labels=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collator\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class FelixCollator:\n",
    "    def __init__(self, tokenizer, pad_label=-100, pad_label_as_input=80):\n",
    "        # change the pad_label_as_input and point_label_as_input\n",
    "        # these must be the len of the label vocab and point_label vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_label = pad_label\n",
    "        self.pad_label_as_input = pad_label_as_input\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # batch is a list of dicts\n",
    "        output_dict = {}\n",
    "        informal_input_ids, informal_attention_mask = [\n",
    "            [i[col] for i in batch]\n",
    "            for col in [\n",
    "                \"informal_input_ids\",\n",
    "                \"informal_attention_mask\",\n",
    "            ]\n",
    "        ]\n",
    "        formal_input_ids = [i[\"formal_input_ids\"] for i in batch]\n",
    "\n",
    "        tag_label = [i[\"tag_labels\"] for i in batch]\n",
    "\n",
    "        tokenized_output = self.tokenizer.pad(\n",
    "            {\n",
    "                \"input_ids\": informal_input_ids,\n",
    "                \"attention_mask\": informal_attention_mask,\n",
    "            },\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        tokenized_output[\"token_type_ids\"] = torch.zeros_like(\n",
    "            tokenized_output[\"input_ids\"]\n",
    "        )\n",
    "\n",
    "        output_label = self.tokenizer.pad(\n",
    "            {\n",
    "                \"input_ids\": formal_input_ids,\n",
    "            },\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        out_label = output_label[\"input_ids\"]\n",
    "        # change pad token to -100\n",
    "        out_label[out_label == self.tokenizer.pad_token_id] = self.pad_label\n",
    "        # print(out_label)\n",
    "        output_dict.update(tokenized_output)\n",
    "        output_dict['labels'] = out_label\n",
    "        # print(output_dict)\n",
    "        # add tag_label to output_dict\n",
    "        # each tag_label is a list of labels (list) with different length\n",
    "        # pad first\n",
    "        max_len = max([len(i) for i in tag_label])\n",
    "        tag_label = [i + [self.pad_label] * (max_len - len(i)) for i in tag_label]\n",
    "        tag_label = torch.tensor(tag_label)\n",
    "\n",
    "        output_dict[\"tag_labels\"] = tag_label\n",
    "        output_dict['tag_labels_input'] = deepcopy(tag_label)\n",
    "        output_dict['tag_labels_input'][output_dict['tag_labels_input'] == self.pad_label] = self.pad_label_as_input\n",
    "\n",
    "        # add point_label to output_dict\n",
    "        # same as above\n",
    "        point_label = [i[\"point_labels\"] for i in batch]\n",
    "        max_len = max([len(i) for i in point_label])\n",
    "        point_label = [i + [self.pad_label] * (max_len - len(i)) for i in point_label]\n",
    "        point_label = torch.tensor(point_label)\n",
    "\n",
    "        output_dict[\"point_labels\"] = point_label\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(data_train, batch_size=2, collate_fn=FelixCollator(tokenizer, pad_label_as_input=len(label_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'labels', 'tag_labels', 'tag_labels_input', 'point_labels'])\n",
      "torch.Size([2, 29])\n",
      "torch.Size([2, 29]) token_type_ids\n",
      "torch.Size([2, 29]) input_ids\n",
      "torch.Size([2, 29]) attention_mask\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for current_batch in loader:\n",
    "    print(current_batch.keys())\n",
    "    input_to_koto = {k: v for k, v in current_batch.items() if k in ['input_ids', 'attention_mask', 'token_type_ids']}\n",
    "    print(current_batch['labels'].shape)\n",
    "    for x in ['token_type_ids', 'input_ids', 'attention_mask']:\n",
    "        print(input_to_koto[x].shape, x)\n",
    "    tag_pred = bert_koto(**input_to_koto, labels=current_batch['tag_labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0,\n",
       " 'SWAP': 1,\n",
       " 'KEEP': 2,\n",
       " 'DELETE': 3,\n",
       " 'KEEP|1': 4,\n",
       " 'KEEP|2': 5,\n",
       " 'KEEP|3': 6,\n",
       " 'KEEP|4': 7,\n",
       " 'KEEP|5': 8,\n",
       " 'KEEP|6': 9,\n",
       " 'KEEP|7': 10,\n",
       " 'KEEP|8': 11,\n",
       " 'KEEP|9': 12,\n",
       " 'KEEP|10': 13,\n",
       " 'KEEP|11': 14,\n",
       " 'KEEP|12': 15,\n",
       " 'KEEP|13': 16,\n",
       " 'KEEP|14': 17,\n",
       " 'KEEP|15': 18,\n",
       " 'KEEP|16': 19,\n",
       " 'KEEP|17': 20,\n",
       " 'KEEP|18': 21,\n",
       " 'KEEP|19': 22,\n",
       " 'KEEP|20': 23,\n",
       " 'KEEP|21': 24,\n",
       " 'KEEP|22': 25,\n",
       " 'KEEP|23': 26,\n",
       " 'KEEP|24': 27,\n",
       " 'KEEP|25': 28}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    4,    3,    3,    3,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    5,    3,    3,    3,    2,    3,    5,    3,    3,    5,    3,\n",
       "            2,    2,    2,    4,    2],\n",
       "        [   2,    2,    4,    3,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    4,    2, -100]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_batch['tag_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=tensor(2.4634, grad_fn=<NllLossBackward0>), logits=tensor([[[-0.2959,  0.3518,  0.3980, -0.0159, -0.4651,  0.5296, -0.7702,\n",
       "          -0.1949,  0.6155,  0.3015,  0.0242, -0.6207],\n",
       "         [ 0.0052,  0.6299, -0.1825, -0.3160, -0.1635,  0.2809, -0.6057,\n",
       "           0.3321,  0.7368,  0.5562, -0.1229, -0.7043],\n",
       "         [ 0.5985, -0.8385,  0.3260, -0.3261,  0.1031,  0.5229, -0.0964,\n",
       "          -0.0522,  0.4766, -0.5926, -0.7479, -0.2680],\n",
       "         [ 0.5692, -0.1968, -0.1931, -0.2463,  0.1139,  0.3532,  0.2381,\n",
       "          -0.0285,  0.0910, -1.0697, -0.7346, -0.2566],\n",
       "         [ 0.3286,  0.3003,  0.0310,  0.4080, -0.2227,  0.0400, -0.5407,\n",
       "          -0.5792, -0.5444, -0.3461, -0.5294, -0.4473],\n",
       "         [ 0.8533, -0.2651, -0.0610,  0.0383,  0.7926,  0.1733, -1.0643,\n",
       "           0.5748, -0.0090,  0.3621,  0.1694, -0.2701],\n",
       "         [-0.3819, -0.3728, -0.1506, -0.4952, -0.8633,  0.0314, -0.2889,\n",
       "           0.0681, -0.3612,  0.3071, -0.0326, -0.3551],\n",
       "         [-0.0512, -0.3576,  0.6773, -0.0871, -0.6164,  0.0429, -0.4089,\n",
       "          -0.6309, -0.1155, -0.3079, -0.7171, -0.4520],\n",
       "         [-0.1168,  0.2980, -0.1505,  0.7076, -0.0095, -0.4498, -0.2689,\n",
       "           0.4879,  0.2616, -0.4450,  0.6566,  0.1814],\n",
       "         [-0.4290,  0.2298, -0.9955,  0.0191, -0.5112,  0.1069, -0.8022,\n",
       "          -0.6145, -0.4730, -0.0691,  0.0026,  0.7317],\n",
       "         [ 0.0822,  0.6751, -0.2852,  0.2423, -0.7498, -0.5089, -0.9185,\n",
       "           0.0161,  0.4986,  0.0051,  0.1921,  0.0390],\n",
       "         [-0.6422,  0.6860,  0.2514,  0.0554,  0.2958, -0.1272,  0.3163,\n",
       "          -0.1809,  0.7244, -0.1323, -0.3464, -0.5904],\n",
       "         [-0.4998,  0.5382,  0.1943,  0.0408, -0.1542, -0.3226,  0.3063,\n",
       "           0.3966, -0.1659, -0.4123,  0.4391, -0.1958],\n",
       "         [ 0.1777,  0.5214,  0.1060,  0.2300, -0.0976, -0.3200, -0.2955,\n",
       "          -0.1214, -0.3199, -0.1687,  0.1563,  0.2943],\n",
       "         [-0.6277, -0.4463, -0.3452, -0.3390,  0.3281, -0.1368,  0.0224,\n",
       "           0.0406, -0.6095, -0.3045, -0.1302,  0.0494],\n",
       "         [-0.3343,  0.3580, -0.1264, -0.4052, -0.4314,  0.2084, -0.5577,\n",
       "          -0.7067, -0.0163, -0.4440,  0.2282,  0.0076],\n",
       "         [-0.4950,  0.1866, -0.6824,  0.0499, -0.1526,  0.0349, -0.3818,\n",
       "          -1.1327, -0.0515, -0.6019,  0.4106, -0.2505],\n",
       "         [-0.9545, -0.1316,  0.0025, -0.2171,  0.1943,  0.5764, -0.4024,\n",
       "          -0.5277, -0.2055,  0.3351, -0.1553,  0.1958],\n",
       "         [-0.5686,  0.3708,  0.0484,  0.4739, -0.1834,  0.4972, -0.9048,\n",
       "          -0.3673,  0.3681,  0.6814,  0.2864,  0.1182],\n",
       "         [ 0.0371, -0.5907,  0.4672,  0.7102,  0.1550, -0.3015, -0.7423,\n",
       "          -0.3510,  0.1646,  0.5364, -0.3102,  0.1006],\n",
       "         [-0.2020,  0.3545, -0.2849,  0.6682, -0.0678,  0.0469, -0.7745,\n",
       "           0.0982,  0.6361,  0.1803,  0.0814, -0.5315],\n",
       "         [ 0.5212, -0.1119, -0.0580,  0.1790, -0.2337, -0.1266, -0.2838,\n",
       "           0.2289, -0.4298,  0.0546,  0.1949,  0.2098],\n",
       "         [ 0.0101,  0.1143,  0.4516,  0.1162, -0.4674, -0.2367, -0.3751,\n",
       "          -0.0281,  0.5607,  0.0642,  0.8637, -0.9311],\n",
       "         [ 0.4367,  1.0097,  0.1197, -0.2115,  0.1532, -0.1250, -0.6026,\n",
       "           0.3011,  0.6388,  0.4333,  0.5402,  0.0177],\n",
       "         [ 0.1778, -0.1790, -0.1751, -0.5805, -0.3232, -0.4287, -0.6466,\n",
       "           0.2991, -0.2005, -0.2959,  0.6063,  0.3352],\n",
       "         [ 0.2122,  0.3576, -0.0026, -0.1993,  0.0062, -0.1407, -0.7577,\n",
       "           0.3065,  0.0251, -0.0257,  0.9494,  0.2296],\n",
       "         [ 0.0729, -0.0127, -0.2073,  0.2568, -0.3812,  0.0528, -0.6673,\n",
       "          -0.4871, -0.5959,  0.0466,  0.5673,  0.5565],\n",
       "         [-0.0362,  0.4627,  0.1763,  0.0887, -0.3958,  0.0132, -0.2256,\n",
       "          -0.2042, -0.0820,  0.1184,  0.9436,  0.2631],\n",
       "         [-0.2213,  0.3389,  0.4245,  0.1563,  0.0743, -0.2685, -0.6230,\n",
       "          -0.4155,  0.2269,  0.7557,  0.7792, -0.3224]],\n",
       "\n",
       "        [[-0.4765,  0.1142,  0.4115, -0.0047,  0.2253,  0.4697, -0.9829,\n",
       "          -0.1885,  0.2828, -0.1780, -0.1697, -0.6384],\n",
       "         [ 0.1319,  0.4108,  0.2250,  0.1016, -0.1490, -0.0218,  0.1289,\n",
       "           0.2293,  0.3192,  0.1862,  0.7513,  0.1921],\n",
       "         [-0.4208,  0.2563, -0.2886, -0.1798,  0.4699,  0.1445, -0.5204,\n",
       "           0.7247, -0.1551, -0.3397,  0.1102,  0.3087],\n",
       "         [ 0.7090,  0.4327,  0.6807,  0.1685,  0.1348,  0.2085, -0.8463,\n",
       "          -0.1038,  0.2817, -0.3352,  0.5140,  0.2400],\n",
       "         [-0.2401,  0.5659,  0.5858,  0.0264, -0.1354, -0.0148, -0.4688,\n",
       "           0.1641,  0.3417, -0.3022,  0.9908, -0.7067],\n",
       "         [ 0.0084,  0.3141, -0.1513, -0.4609,  0.2340, -1.2305, -0.6468,\n",
       "           0.2046, -0.8661, -0.3827,  0.1050, -0.0479],\n",
       "         [ 0.2878, -0.0683,  0.1961, -0.7775,  0.0960, -0.6219, -0.3177,\n",
       "          -0.1811, -0.8848, -0.5510, -0.2050,  0.5181],\n",
       "         [ 0.0731,  0.2777,  0.3999, -0.7579, -0.0282, -0.1574, -0.0217,\n",
       "          -0.5453, -0.4992, -0.2934,  0.2032,  0.9713],\n",
       "         [ 0.4537,  0.2541,  0.6193, -0.6698,  0.0536,  0.0308,  0.2167,\n",
       "          -0.3930,  0.0233,  0.0721, -0.2949,  0.3104],\n",
       "         [-0.0786, -0.2872,  0.2786, -0.3141,  0.0101,  0.1326, -0.1666,\n",
       "           0.1186,  0.0169, -0.0078,  0.0871,  0.0166],\n",
       "         [ 0.4000, -0.5283,  0.1141,  0.2356,  0.2249, -0.0782,  0.0558,\n",
       "          -0.0619, -0.2375,  0.5360, -0.2089, -0.0241],\n",
       "         [ 0.2794,  0.0691,  0.5857, -0.0534,  0.4294, -0.0363, -0.5185,\n",
       "           0.4439, -0.1226,  0.3577, -0.2013,  0.1292],\n",
       "         [-0.0597, -0.4805,  0.3095,  0.0107,  0.3305, -0.8556, -0.4287,\n",
       "           0.0053, -0.6171,  0.8783, -0.4490,  0.1453],\n",
       "         [-0.5778,  0.7500, -0.4468, -0.7137,  0.6282, -0.9837, -0.5961,\n",
       "           0.2378, -0.5113,  0.0667, -0.1964, -0.4781],\n",
       "         [-0.4600,  0.4995,  0.0725, -0.7222,  0.6082, -0.5171,  0.0658,\n",
       "           0.2308, -0.6940, -0.6545, -0.1960, -0.1012],\n",
       "         [-0.1897,  0.2524, -0.1380, -0.2671,  0.2938, -0.5256,  0.3594,\n",
       "           0.1948, -0.6234, -0.8873,  0.3103,  0.5095],\n",
       "         [-0.9186,  0.3274, -0.0665, -0.6450,  0.3376, -0.2527,  0.4678,\n",
       "           0.1799, -1.1575, -0.2668, -0.5732,  0.0108],\n",
       "         [ 0.1105, -0.0565,  0.1584,  0.0060,  0.5595, -0.6637, -0.4955,\n",
       "          -0.0758, -0.6417,  0.0901, -0.2112,  0.2581],\n",
       "         [-0.4166,  0.5799,  0.0441, -0.0322,  0.2766, -0.6194, -0.2516,\n",
       "          -0.2867, -0.8871,  0.0551, -0.2093,  0.2548],\n",
       "         [-0.1731,  0.9359,  0.1709,  0.1482, -0.1125, -0.6397, -0.3404,\n",
       "          -0.5683, -0.9556, -0.3084, -0.6051,  1.1128],\n",
       "         [-0.2460,  0.9256,  0.5023, -0.4553,  0.3761, -0.3412, -0.1098,\n",
       "          -0.5030, -1.0037,  0.0108, -0.5817,  0.7662],\n",
       "         [-0.4188,  0.2319,  0.2842, -0.0631,  0.1796, -0.8025,  0.0395,\n",
       "          -0.0333, -0.7758,  0.4530, -0.5296,  0.1287],\n",
       "         [-0.9997, -0.1759,  0.0036, -0.8594,  0.0799, -0.8260, -1.1587,\n",
       "          -0.3989, -0.9508,  0.0290, -0.7029, -0.6878],\n",
       "         [-0.4058, -0.2167, -0.5024, -0.4433,  0.3706, -1.2411, -0.2989,\n",
       "          -0.9839, -0.2992, -0.0751,  0.4479, -0.1661],\n",
       "         [-0.4256, -0.3311,  0.1229,  0.4452, -0.3352, -0.2364, -0.5478,\n",
       "           0.1286, -0.4908, -0.1267,  0.8548, -1.0957],\n",
       "         [-0.1101,  0.0167, -0.6109,  0.1644,  0.1838, -0.3791, -0.5938,\n",
       "           0.7708, -0.3732,  0.4607,  0.5434, -0.5009],\n",
       "         [-0.8813,  0.0957, -0.2480, -0.0933, -0.0027, -0.0522, -0.7861,\n",
       "          -0.2758, -0.2561,  0.1444,  0.7293, -0.1595],\n",
       "         [-0.0621, -0.3788, -0.2809,  0.0788, -0.0967, -0.1663, -0.9670,\n",
       "           0.1675, -0.5052,  0.6629,  0.6536, -1.0712],\n",
       "         [-0.1514, -0.5488, -0.1383,  0.1198, -0.1617,  0.1862, -0.9956,\n",
       "           0.1747, -0.5899,  0.5681,  0.5535, -0.9914]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_batch = next(iter(loader))\n",
    "\n",
    "input_to_koto = {k: v for k, v in current_batch.items() if k in ['input_ids', 'attention_mask', 'token_type_ids']}\n",
    "input_to_koto['labels'] = current_batch['tag_labels']\n",
    "bert_koto(**input_to_koto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    3, 11450,  1862,   932,   945, 10121,    66,  8014,  1604,   962,\n",
       "           1843,  2587,  4207,   933, 17849, 17104, 21463, 12411,  1476,    16,\n",
       "          14099, 17849,    18, 21140, 18070,  6359,   962, 10155,     4],\n",
       "         [    3,  4863,  6097,  2118,    18,  1731,  2882,  3888,  6505,  1881,\n",
       "          10896,  4362,    16,  1925,  2643,  6813,     6,  2022,  4942,  1560,\n",
       "           2289,     6,  9153, 23120,    18,  5218,  3774,     4,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]),\n",
       " 'labels': tensor([[    3, 11450,  1818, 10121,    66,  8014,  1604,   962,  1843,  2587,\n",
       "           4207,   933,  2460,  3716, 12411,    16,  3005,  1975,    18,  5218,\n",
       "           3774, 18070,  6359,   962, 10155,    18,     4,  -100,  -100],\n",
       "         [    3,  4863,  6097,  4374,    18,  1731,  2882,  3888,  6505,  1881,\n",
       "          10896,  4362,  1925,  2643,  6813,    16,     6,  2022,  4942,  1560,\n",
       "           2289,     6,  9153, 23120,    18,  5218,  3774,    18,     4]]),\n",
       " 'tag_labels': tensor([[   2,    4,    3,    3,    3,    2,    2,    2,    2,    2,    2,    2,\n",
       "             2,    5,    3,    3,    3,    2,    3,    5,    3,    3,    5,    3,\n",
       "             2,    2,    2,    4,    2],\n",
       "         [   2,    2,    4,    3,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "             2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "             2,    2,    4,    2, -100]]),\n",
       " 'tag_labels_input': tensor([[ 2,  4,  3,  3,  3,  2,  2,  2,  2,  2,  2,  2,  2,  5,  3,  3,  3,  2,\n",
       "           3,  5,  3,  3,  5,  3,  2,  2,  2,  4,  2],\n",
       "         [ 2,  2,  4,  3,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  2,  2,  2,  2,  4,  2, 80]]),\n",
       " 'point_labels': tensor([[   1,    5,    0,    0,    0,    6,    7,    8,    9,   10,   11,   12,\n",
       "            13,   17,    0,    0,    0,   19,    0,   22,    0,    0,   24,    0,\n",
       "            25,   26,   27,   28,    0],\n",
       "         [   1,    2,    4,    0,    5,    6,    7,    8,    9,   10,   11,   13,\n",
       "            16,   14,   15,   12,   17,   18,   19,   20,   21,   22,   23,   24,\n",
       "            25,   26,   27,    0, -100]])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertLayer, BertConfig, BertAttention\n",
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers.models.bert.modeling_bert import BertSelfAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, pointer_config) -> None:\n",
    "        super().__init__()\n",
    "        self.pointer_config = pointer_config\n",
    "        self.bert = BertModel(pointer_config)\n",
    "        self.last_attention = BertSelfAttention(pointer_config)\n",
    "        self.nll_loss = NLLLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "        bert_output = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        input_shape = input_ids.size()\n",
    "        extended_attention_mask: torch.Tensor = self.bert.get_extended_attention_mask(\n",
    "            attention_mask, input_shape\n",
    "        )\n",
    "        # print(bert_output[0].shape)\n",
    "        _, last_attention = self.last_attention(\n",
    "            bert_output[0], extended_attention_mask, output_attentions=True\n",
    "        )\n",
    "        if labels is not None:\n",
    "            loss = self.nll_loss(last_attention.view(-1, last_attention.shape[-1]), labels.view(-1))\n",
    "            return loss, last_attention\n",
    "        return None, last_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_network_config = BertConfig(\n",
    "    vocab_size=len(label_dict) + 1,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=1,\n",
    "    pad_token_id=len(label_dict),\n",
    ")  # + 1 as the pad token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_network = PointerNetwork(pointer_network_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_pointer = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'labels', 'tag_labels', 'tag_labels_input', 'point_labels'])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_pointer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_pointer_real = {\n",
    "    k: v for k, v in input_to_pointer.items() if k in ['tag_labels_input', 'attention_mask', 'token_type_ids']\n",
    "}\n",
    "input_to_pointer_real['input_ids'] = input_to_pointer_real.pop('tag_labels_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_pointer_real['input_ids'] = input_to_pointer_real.pop('tag_labels_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_out = pointer_network(**input_to_pointer_real)\n",
    "# make it as log softmax\n",
    "softmax_out = torch.nn.LogSoftmax(dim=-1)(softmax_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3638, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLLLoss()(softmax_out.view(-1, softmax_out.shape[-1]), input_to_pointer['point_labels'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pointer network\n",
    "tag_embedding = torch.nn.Embedding(12,5)\n",
    "pos_embedding = torch.nn.Embedding(100,5)\n",
    "\n",
    "# Linear SWISH GELU\n",
    "linear = torch.nn.Linear(5,5)\n",
    "swish = torch.nn.SiLU()\n",
    "gelu = torch.nn.GELU()\n",
    "\n",
    "# 2x encoder\n",
    "encoder = BertLayer(pointer_config)\n",
    "\n",
    "# Attention Layer! (single head)\n",
    "attention = BertAttention(pointer_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
