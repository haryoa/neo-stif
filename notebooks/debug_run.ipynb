{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haryoaw/documents/courses/nlp802/project/texteditalay\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "from transformers import AutoTokenizer, BertForTokenClassification, BertConfig, BertForMaskedLM\n",
    "from neo_stif.components.utils import create_label_map\n",
    "import pandas as pd\n",
    "from neo_stif.components.train_data_preparation import prepare_data_tagging_and_pointer\n",
    "import datasets\n",
    "from neo_stif.lit import LitPointer, LitTaggerOrInsertion\n",
    "from torch.utils.data import DataLoader\n",
    "from neo_stif.components.collator import FelixCollator, FelixInsertionCollator\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import RichProgressBar, ModelCheckpoint, EarlyStopping\n",
    "from neo_stif.components.utils import compute_class_weights\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "MAX_MASK = 30\n",
    "USE_POINTING = True\n",
    "\n",
    "\n",
    "model_dict = {\"koto\": \"indolem/indobert-base-uncased\"}\n",
    "\n",
    "\n",
    "LR_TAGGER = 5e-5 # due to the pre-trained nature\n",
    "LR_POINTER = 1e-5 # no pre-trained\n",
    "LR_INSERTION = 2e-5 # due to the pre-trained nature\n",
    "VAL_CHECK_INTERVAL = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1922/1922 [00:00<00:00, 10740.51 examples/s]\n",
      "Map: 100%|██████████| 1922/1922 [00:01<00:00, 1319.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"indolem/indobert-base-uncased\")\n",
    "label_dict = create_label_map(MAX_MASK, USE_POINTING)\n",
    "\n",
    "# Callback for trainer\n",
    "\n",
    "df_train = pd.read_csv(\"data/stif_indo/train_with_pointing.csv\")\n",
    "data_train = datasets.Dataset.from_pandas(df_train)\n",
    "data_train, label_dict = prepare_data_tagging_and_pointer(\n",
    "    data_train, tokenizer, label_dict\n",
    ")\n",
    "model_path_or_name = model_dict[\"koto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "processed_train_data = \"data/stif_indo/train_insertion\"\n",
    "processed_dev_data = \"data/stif_indo/dev_insertion\"\n",
    "batch_size=2\n",
    "device=\"cpu\"\n",
    "rich_cb = RichProgressBar()\n",
    "\n",
    "ea_stop = EarlyStopping(patience=5, monitor=\"val_loss\", mode=\"min\")\n",
    "train_data = load_from_disk(processed_train_data)\n",
    "dev_data = load_from_disk(processed_dev_data)\n",
    "train_dl = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=FelixInsertionCollator(tokenizer),\n",
    ")\n",
    "dev_dl = DataLoader(\n",
    "    dev_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=FelixInsertionCollator(tokenizer),\n",
    ")\n",
    "model = BertForMaskedLM.from_pretrained(model_path_or_name)\n",
    "lit_insert = LitTaggerOrInsertion(\n",
    "    model,\n",
    "    lr=LR_INSERTION,\n",
    "    num_classes=model.config.vocab_size,\n",
    "    class_weight=None,\n",
    "    tokenizer=tokenizer,\n",
    "    label_dict=label_dict,\n",
    "    is_insertion=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    accelerator=device,\n",
    "    devices=1,\n",
    "    val_check_interval=20,\n",
    "    check_val_every_n_epoch=None,\n",
    "    callbacks=[rich_cb, ea_stop],\n",
    "    fast_dev_run=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model   │ BertForMaskedLM  │  110 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ ce_loss │ CrossEntropyLoss │      0 │\n",
       "└───┴─────────┴──────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model   │ BertForMaskedLM  │  110 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ ce_loss │ CrossEntropyLoss │      0 │\n",
       "└───┴─────────┴──────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 110 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 110 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 442                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 110 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 110 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 442                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/haryoaw/mambaforge/envs/sensei/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">31923\n",
       "</pre>\n"
      ],
      "text/plain": [
       "31923\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Input before going to output: [('[CLS]', 'IGNORED'), ('[MASK]', 'admin'), ('[UNK]', 'IGNORED'), ('min', 'IGNORED'),\n",
       "('[PAD]', 'IGNORED'), (',', 'IGNORED'), ('promo', 'IGNORED'), ('\"', 'IGNORED'), ('makan', 'IGNORED'), (',', \n",
       "'IGNORED'), ('jajan', 'IGNORED'), ('bareng', 'IGNORED'), ('\"', 'IGNORED'), ('[MASK]', 'jika'), ('[MASK]', 'belum'),\n",
       "('[MASK]', 'premium'), ('[UNK]', 'IGNORED'), ('kalo', 'IGNORED'), ('bel', 'IGNORED'), ('##om', 'IGNORED'), \n",
       "('premi', 'IGNORED'), ('##un', 'IGNORED'), ('[PAD]', 'IGNORED'), (',', 'IGNORED'), ('cash', 'IGNORED'), ('##back', \n",
       "'IGNORED'), ('[MASK]', '##nya'), ('[MASK]', 'dapat'), ('[UNK]', 'IGNORED'), ('nya', 'IGNORED'), ('dapet', \n",
       "'IGNORED'), ('[PAD]', 'IGNORED'), ('berapa', 'IGNORED'), ('?', 'IGNORED'), ('[SEP]', 'IGNORED')]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Input before going to output: [('[CLS]', 'IGNORED'), ('[MASK]', 'admin'), ('[UNK]', 'IGNORED'), ('min', 'IGNORED'),\n",
       "('[PAD]', 'IGNORED'), (',', 'IGNORED'), ('promo', 'IGNORED'), ('\"', 'IGNORED'), ('makan', 'IGNORED'), (',', \n",
       "'IGNORED'), ('jajan', 'IGNORED'), ('bareng', 'IGNORED'), ('\"', 'IGNORED'), ('[MASK]', 'jika'), ('[MASK]', 'belum'),\n",
       "('[MASK]', 'premium'), ('[UNK]', 'IGNORED'), ('kalo', 'IGNORED'), ('bel', 'IGNORED'), ('##om', 'IGNORED'), \n",
       "('premi', 'IGNORED'), ('##un', 'IGNORED'), ('[PAD]', 'IGNORED'), (',', 'IGNORED'), ('cash', 'IGNORED'), ('##back', \n",
       "'IGNORED'), ('[MASK]', '##nya'), ('[MASK]', 'dapat'), ('[UNK]', 'IGNORED'), ('nya', 'IGNORED'), ('dapet', \n",
       "'IGNORED'), ('[PAD]', 'IGNORED'), ('berapa', 'IGNORED'), ('?', 'IGNORED'), ('[SEP]', 'IGNORED')]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Input, pred: [('[CLS]', ','), ('[MASK]', ','), ('[UNK]', '[UNK]'), ('min', 'min'), ('[PAD]', ')'), (',', ','), \n",
       "('promo', 'promo'), ('\"', '\"'), ('makan', 'makan'), (',', ','), ('jajan', 'jajan'), ('bareng', 'bareng'), ('\"', \n",
       "'\"'), ('[MASK]', ','), ('[MASK]', '.'), ('[MASK]', '##back'), ('[UNK]', '[UNK]'), ('kalo', 'kalo'), ('bel', 'bel'),\n",
       "('##om', '##om'), ('premi', 'premi'), ('##un', '##un'), ('[PAD]', ','), (',', ','), ('cash', 'cash'), ('##back', \n",
       "'##back'), ('[MASK]', '##nya'), ('[MASK]', ','), ('[UNK]', '[UNK]'), ('nya', 'nya'), ('dapet', 'dapet'), ('[PAD]', \n",
       "'berapa'), ('berapa', 'berapa'), ('?', '?'), ('[SEP]', '.')]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Input, pred: [('[CLS]', ','), ('[MASK]', ','), ('[UNK]', '[UNK]'), ('min', 'min'), ('[PAD]', ')'), (',', ','), \n",
       "('promo', 'promo'), ('\"', '\"'), ('makan', 'makan'), (',', ','), ('jajan', 'jajan'), ('bareng', 'bareng'), ('\"', \n",
       "'\"'), ('[MASK]', ','), ('[MASK]', '.'), ('[MASK]', '##back'), ('[UNK]', '[UNK]'), ('kalo', 'kalo'), ('bel', 'bel'),\n",
       "('##om', '##om'), ('premi', 'premi'), ('##un', '##un'), ('[PAD]', ','), (',', ','), ('cash', 'cash'), ('##back', \n",
       "'##back'), ('[MASK]', '##nya'), ('[MASK]', ','), ('[UNK]', '[UNK]'), ('nya', 'nya'), ('dapet', 'dapet'), ('[PAD]', \n",
       "'berapa'), ('berapa', 'berapa'), ('?', '?'), ('[SEP]', '.')]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(lit_insert, train_dl, dev_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
